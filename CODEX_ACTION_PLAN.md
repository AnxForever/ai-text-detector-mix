# Codex建议执行方案

> 基于Codex分析的最小可行路线

---

## 🎯 核心策略

### Codex的关键建议
1. **先装环境并训练长度平衡模型** - 快速得到"纠偏后基线"
2. **立刻做统计特征融合** - 轻量，快速见效
3. **再扩充数据** - HC3/THUCNews/NLPCC
4. **最后做图增强+多任务** - 作为中后期强化

---

## ✅ 立即执行（今天）

### 步骤1：安装环境
```bash
cd /mnt/c/datacollection
bash install_pytorch.sh
```

### 步骤2：启动训练
```bash
bash quick_start_training.sh
```

### 步骤3：等待训练完成（2-4小时）
- 监控训练进度
- 查看验证集性能
- 记录关键指标

---

## 📊 最小可行论文路线（4步）

### 1. 发现问题 ✅
- AI平均1680字 vs 人类942字
- 差距78%
- 风险：模型学到"长文本=AI"

### 2. 提出方案 ✅
- 长度分层采样
- 截断过长文本（>2500）
- 按长度区间平衡

### 3. 验证效果 🔄（本周）
- 训练纠偏后模型
- 长度分段评估
- 证明不依赖长度

### 4. 轻量增强 ⏳（下周）
- 统计特征融合
- BERT vs BERT+统计对比

---

## 📈 最少模型变体（4个）

| 模型 | 状态 | 用途 |
|------|------|------|
| 1. 原始BERT（未纠偏） | ✅ 已有 | Baseline |
| 2. 纠偏后BERT | 🔄 训练中 | 核心贡献 |
| 3. BERT + 统计特征 | ⏳ 下周 | 轻量增强 |
| 4. 跨数据集测试 | ⏳ 第3周 | 泛化验证 |

---

## 🎓 论文贡献点

### 核心贡献（必须）
1. **发现长度偏差问题** - 首次系统量化
2. **提出纠偏方案** - 长度分层采样
3. **验证有效性** - 纠偏前后对比

### 加分贡献（可选）
4. 统计特征融合
5. 图结构分析
6. 多任务学习

---

## ⏰ 时间规划

### 本周（第1周）
- [x] 环境安装
- [ ] 长度平衡模型训练
- [ ] 长度分段评估
- [ ] 纠偏前后对比

### 下周（第2周）
- [ ] 统计特征提取
- [ ] 混合特征模型训练
- [ ] 对比实验

### 第3周
- [ ] 收集HC3/THUCNews
- [ ] 跨数据集测试
- [ ] 整理实验结果

### 第4周
- [ ] 论文核心章节撰写
- [ ] 图表制作
- [ ] 实验补充

---

## 📋 数据策略

### 当前数据（13,829条）
**够用于**：
- ✅ 核心论文主线
- ✅ 长度偏差验证
- ✅ 统计特征融合

**不够用于**：
- ❌ 强泛化展示
- ❌ 跨域测试

### 扩充计划
- **阶段1**（现在）：用13,829条完成核心实验
- **阶段2**（后续）：扩充到20,000+
- **阶段3**（可选）：扩充到50,000+

---

## 🔧 技术路线

### 核心路线（必做）
1. ✅ 长度平衡BERT
2. ⏳ BERT + 统计特征
3. ⏳ 跨数据集测试

### 加分模块（可选）
4. 图统计特征（简单版）
5. GCN（复杂版）
6. 多任务学习

### 实施顺序
```
统计特征融合（最快）
    ↓
图统计特征（中等）
    ↓
GCN（较重）
    ↓
多任务（中后期）
```

---

## 🎯 两周内目标

### 核心产出
- [x] 纠偏后模型结果稳定
- [ ] 统计特征融合模型完成
- [ ] 论文核心贡献链条形成

### 实验数据
- [ ] 4个模型对比
- [ ] 长度分段评估
- [ ] 纠偏前后对比
- [ ] 统计特征消融

---

## 📞 关键文件

- **任务清单**：`WEEKLY_TASKS.md`
- **快速启动**：`quick_start_training.sh`
- **环境安装**：`install_pytorch.sh`
- **6个月计划**：`ENHANCEMENT_PLAN_6MONTHS.md`

---

## 🚀 现在就开始

```bash
# 1. 安装环境
bash install_pytorch.sh

# 2. 启动训练
bash quick_start_training.sh

# 3. 查看任务
cat WEEKLY_TASKS.md
```

---

**Codex的核心观点**：
> "你当前最大风险是没有纠偏后的模型结果，而这恰好是你论文最核心的贡献点之一。"

**行动**：立即训练长度平衡模型！
