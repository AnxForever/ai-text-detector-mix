# AI文本检测数据集后续构建方案（v1.0）

> 面向后续数据构建迭代的执行方案，强调多域、多模型、多场景与可复现。
> 适配现有“六维组合生成”框架，并补齐跨域、对抗与混合写作样本。

---

## 1. 目标与原则

**目标**
- 提升跨域、跨模型、跨时间的泛化能力
- 消除格式偏差，保证语义学习而非表面特征
- 构建可扩展、可复现、可审计的数据流水线

**原则**
- 真实人类语料为基线，AI生成数据为补充
- 覆盖多种体裁、角色、风格、约束与提示类型
- 全流程记录元数据，确保可追溯

---

## 2. 数据范围与规模（建议版）

**语言**
- 以中文为主（简体），保留后续扩展多语言的接口

**文本类型与领域**
- 领域：科技、社会、经济、教育、健康、文化、学术、对话
- 类型：说明、议论、记叙、描写、抒情
- 体裁：新闻、评论、科普、访谈、随笔、学术短文、对话

**长度分布**
- 100-300 / 300-600 / 600-1200 / 1200-2000 字，按配额均衡

**规模建议**
- 基线版：AI 2-3 万 + 人类 2-3 万 + 难例 5 千
- 标准版：AI 6-8 万 + 人类 6-8 万 + 难例 1-2 万
- 扩展版：AI 15 万 + 人类 15 万 + 难例 3 万

---

## 3. 数据来源与覆盖策略

**人类语料**
- 现有 THUCNews 继续保留
- 新增多域语料（需确认版权与许可）
- 领域内按主题与长度分层抽样，避免偏斜

**AI语料**
- 多模型覆盖：OpenAI / Anthropic / Google / DeepSeek / 阿里（Qwen）
- 每个模型使用 3 组解码配置（低/中/高随机性）
- 生成分布与人类语料在领域、长度、体裁上对齐

---

## 4. 生成设计（基于六维组合扩展）

**保留六维**
- 主题 / 文体 / 角色 / 风格 / 约束 / 属性

**新增控制维度**
- 提示类型：指令、续写、改写、对话、摘要
- 写作任务：解释、比较、立论、评述、叙事
- 生成温度档位：低/中/高

**组合策略**
- 先生成全量组合池，再按语义合理性评分筛选
- 每个组合在不同模型与解码配置下生成 1-2 个变体
- 设定去重与语义相似度阈值，避免重复

---

## 5. 难例与对抗样本构造

**人性化改写**
- 同义改写、语序扰动、语气调整、口语化

**后编辑样本**
- AI生成 -> 人工润色（或模拟编辑）-> 作为难例

**混合写作样本**
- 人类段落 + AI段落拼接
- 提供段落级边界标签与混合比例

**跨模型一致性**
- 同一主题由不同模型生成多个版本，构成“模型对抗集”

---

## 6. 清洗与质量控制

**规则清洗**
- 去除 Markdown / 列表格式 / 过度模板化输出
- 长度过滤、异常字符过滤、重复内容清理

**质量评分**
- 连贯性、信息密度、结构完整性、模板痕迹
- 低质量样本丢弃或回收重写

**隐私与敏感信息**
- 对实体信息做脱敏或替换
- 明确不收集个人隐私内容

---

## 7. 标注与元数据规范

**保留现有字段**
- text_id, text_content, source_api, source_model
- attribute, topic, genre, role, style, constraint
- prompt, combination_quality, generation_quality, length, timestamp

**新增建议字段**
- domain, prompt_type, task_type
- decoding_profile, model_family, rewrite_type
- mix_ratio, segment_labels, source_license

**数据卡与版本记录**
- 记录来源、比例、采样策略、清洗规则与评估结果

---

## 8. 划分与评估方案

**数据切分**
- 按主题/提示/时间/模型分层切分，避免信息泄漏
- 保留跨域、跨模型、跨长度的独立测试集

**评估维度**
- 基础指标：Accuracy / F1 / AUC
- 泛化能力：跨域、跨模型
- 鲁棒性：改写、混合、格式扰动
- 偏差审计：领域、长度、体裁的子集稳定性

---

## 9. 版本化与治理

**版本策略**
- v2.0：引入多域 + 多模型 + 多解码
- v2.1：加入混合写作 + 人性化改写
- v2.2：加入跨时间更新与公平性审计

**治理**
- 每次迭代输出变更说明与数据卡
- 记录数据来源、授权、生成配置与清洗规则

---

## 10. 执行计划与里程碑（可调整）

**阶段 0：需求确认（1-2 天）**
- 规模目标、预算、模型可用性、领域优先级确认

**阶段 1：语料与主题池扩展（3-5 天）**
- 人类语料补充与分层
- 主题池/提示池扩充与审核

**阶段 2：多模型生成（5-10 天）**
- 多模型、多解码批量生成
- 组合池与采样策略落地

**阶段 3：清洗与质量评估（3-5 天）**
- 规则过滤 + 质量评分
- 去重与混合样本构造

**阶段 4：评估与发布（2-3 天）**
- 完成基线评估与鲁棒性测试
- 生成数据卡与版本报告

---

## 11. 风险与对策

| 风险 | 影响 | 对策 |
|---|---|---|
| 格式偏差回归 | 模型学到表面特征 | 统一格式输出 + 格式扰动对抗 |
| 领域分布失衡 | 泛化能力下降 | 分层采样 + 领域配额 |
| 模型覆盖不足 | 跨模型泛化差 | 增加模型家族与解码配置 |
| 许可/版权风险 | 数据不可公开 | 严格来源审查与记录 |
| 成本与API稳定性 | 生成进度受阻 | 分批生成 + 断点续跑 |

---

## 12. 待确认事项

1. 目标规模选择（基线/标准/扩展）
2. 模型访问清单与预算
3. 领域优先级与语料许可
4. 是否需要多语言版本

---

**版本**：v1.0  
**更新时间**：2026-01-20
