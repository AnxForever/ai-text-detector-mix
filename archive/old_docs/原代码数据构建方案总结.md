# 原代码数据构建方案总结

## 一、核心架构：六维组合框架

### 1. 六个维度（Six Dimensions）
| 维度 | 数量 | 生成方式 | 缓存时长 |
|------|------|---------|---------|
| **话题** (Topics) | 50个 | LLM自动生成 | 24小时 |
| **文体** (Genres) | 20个 | LLM自动生成 | 24小时 |
| **角色** (Roles) | 15个 | LLM自动生成 | 24小时 |
| **风格** (Styles) | 10个 | LLM自动生成 | 24小时 |
| **约束** (Constraints) | 8个 | LLM自动生成 | 24小时 |
| **属性** (Attributes) | 5个 | 固定预设 | - |

**属性固定值：**
- 描写、记叙、说明、抒情、议论

### 2. 话题生成策略（第98-156行）
```python
num_topics = 30  # 默认30个话题
categories = ["科技与创新", "社会与民生", "经济与商业", "教育与学习",
              "健康与医疗", "环境与生态", "文化与艺术", "哲学与思考"]

话题类型分布：
- 30% 当前社会热点问题
- 30% 长期存在的根本性问题
- 20% 未来趋势与预测性话题
- 20% 跨学科交叉话题
```

**特点：**
- 使用LLM生成，temperature=0.8（较高创造性）
- 话题长度过滤：5-100字符
- 有8个备用默认话题（如"人工智能对创意产业的影响"）

---

## 二、智能组合生成机制

### 1. 组合策略（第421-507行）
```python
num_combinations = 800  # 每个模型生成800个组合

组合生成流程：
1. 随机选择属性（5选1）
2. 随机选择话题（50选1）
3. 智能匹配角色（基于话题关键词）
4. 智能匹配文体（基于角色和话题）
5. 智能匹配风格（基于文体）
6. 随机选择约束（8选1）
```

### 2. 智能匹配逻辑

**角色匹配（第509-539行）：**
- 科技话题 → 技术相关角色（科学家、工程师、研究员）
- 社会话题 → 公众角色（市民、居民、消费者）
- 经济话题 → 商业角色（分析师、企业家、投资者）
- 其他 → 随机选择

**文体匹配（第541-561行）：**
- 学生角色 → 教育类文体（作文、日记、读后感）
- 专业角色 → 专业文体（论文、报告、研究）
- 普通公众 → 媒体文体（博客、文章、问答）

**风格匹配（第563-595行）：**
- 正式文体 → 严谨风格（学术、客观、批判）
- 媒体文体 → 活泼风格（幽默、热情、故事性）
- 创意文体 → 文学风格（诗意、抒情、感染力）

### 3. 质量评分系统（第619-642行）
```python
基础分：0.5

加分项：
+ 0.1  话题长度合理（10-80字）
+ 0.2  角色与话题匹配
+ 0.1  文体与风格匹配
+ 0.05 约束简洁（<50字）
+ 0-0.05 随机多样性分

最终分数：0.5 - 1.0
```

组合按质量降序排列，优先生成高质量组合。

---

## 三、提示词构建（第597-617行）

### 提示词结构
```
【任务】{属性指令}
【主题】{话题}
【你的角色】请以{角色}的身份进行写作。
【文体与发布平台】请写成一篇{文体}。
【语言风格】整体文风请保持{风格}。
【特殊要求】{约束}。

请综合以上所有要求，创作一篇完整、连贯的文章。
```

**属性指令示例：**
- 描写："请对以下主题进行具体、细腻的**描写**，聚焦于感官细节和画面营造"
- 议论："请就以下主题，发表明确的观点并进行有力的**议论**和论证"

---

## 四、API调用与容错

### 1. 多模型配置（第13-33行）
```python
MODEL_CONFIGS = {
    "custom": {
        "api_key": "...",
        "base_url": "https://china.184772.xyz/v1",
        "model_name": "gpt-4o-mini"
    },
    "deepseek": {
        "api_key": "...",
        "base_url": "https://api.deepseek.com",
        "model_name": "deepseek-chat"
    },
    "qwen": {
        "api_key": "...",
        "base_url": "https://dashscope.aliyuncs.com/compatible-mode/v1",
        "model_name": "qwen3-max"
    }
}
```

### 2. 重试机制（第675-703行）
```python
max_retries = 3
重试策略：指数退避（5秒、10秒、15秒）

容错处理：
- API错误 → 自动重试
- 其他错误 → 跳过样本
- 模型未配置 → 跳过模型
```

### 3. 请求参数
```python
max_tokens = 2000
temperature = 0.7
请求间隔 = 0.5秒（防止频率限制）
```

---

## 五、主控制流程（第750-960行）

### 1. 生成配置
```python
SAMPLES_PER_MODEL = 800  # 每个模型生成800条
ACTIVE_MODELS = ["custom", "deepseek", "qwen"]  # 所有可用模型
OUTPUT_DIR = "auto_generated_datasets"
```

### 2. 执行流程
```
1. 检测可用API客户端
2. 初始化维度生成器和组合生成器
3. 生成或加载组合计划（800个组合）
4. 按质量排序组合
5. 遍历每个模型：
   a. 为每个模型生成800条数据
   b. 使用同一套组合计划
   c. 每20条保存一次进度
   d. 自动保存到CSV文件
6. 最后合并所有模型的数据
```

### 3. 断点续传
- 组合计划保存到 `auto_generation_plan.json`
- 记录每个样本的 `generated_{model_name}` 标记
- 重启后自动加载计划，跳过已生成样本

### 4. 数据保存（第863-883行）
```python
保存间隔：每20条
编码格式：UTF-8-SIG
保存模式：首次覆盖，后续追加

输出文件：
- auto_dataset_custom_20260106_1408.csv
- auto_dataset_deepseek_20260106_1610.csv
- auto_dataset_qwen_20260106_1620.csv
```

---

## 六、质量评估（第708-745行）

### TextQualityAssessor 评估维度
```python
基础分：0.5

评估项：
1. 长度检查（+0.2）
   - 约束要求≥400字 → 实际≥300字
   - 无约束 → 实际≥100字

2. 结构检查（+0.1）
   - 包含段落分隔（\n\n）
   - 或至少3个句子（。）

3. 内容检查（+0.1）
   - "三个分论点"约束 → 检测"首先、其次、第一、第二"等

4. 修辞检查（+0.1）
   - "比喻/类比"约束 → 检测"像、如同、好比"等

5. 去AI化（+0.1）
   - 不含"作为一个AI"
   - 不含"很抱歉"、"无法完成"等拒绝模板

最终分数：0.5 - 1.0（大部分在0.9左右）
```

---

## 七、输出数据结构

### CSV字段（14列）
```python
{
    "text_id": "custom_131",           # 模型名_组合ID
    "text_content": "完整文本内容...",   # 生成的文本
    "source_model": "custom",          # 来源模型
    "attribute": "描写",               # 属性
    "topic": "数据隐私与商业创新...",   # 话题
    "genre": "项目进展报告",            # 文体
    "role": "项目经理",                # 角色
    "style": "严谨客观",               # 风格
    "constraint": "全文不少于400字",    # 约束
    "prompt": "【任务】...",           # 完整提示词
    "combination_quality": 0.85,       # 组合质量分
    "generation_quality": 0.90,        # 生成质量分
    "length": 1204,                    # 文本长度
    "timestamp": "2026-01-06T14:08:43" # 生成时间
}
```

---

## 八、关键特点总结

### ✅ 优势
1. **高度自动化**：维度完全由LLM生成，无需人工配置
2. **智能匹配**：角色-话题-文体-风格四级联动匹配
3. **质量控制**：组合质量预评估 + 生成质量后评估
4. **缓存机制**：24小时缓存减少重复API调用
5. **容错能力**：自动重试、断点续传、进度保存
6. **多模型支持**：统一接口支持3个模型并行生成

### ❌ 局限性
1. **单一数据源**：100% AI生成，缺少人类样本
2. **模型单一性**：实际只用了custom，另外两个模型未启用
3. **话题重复**：50个话题生成800条，平均16次重复
4. **格式统一**：86.7%文本含Markdown标记
5. **规模受限**：每个模型仅800条，总计2400条（3模型）
6. **AI特征明显**：逻辑连接词密集，无自然变异

---

## 九、实际生成统计（当前运行）

### 已完成数据
```
✅ CUSTOM: 800/800 条 (100%)
🔄 DEEPSEEK: 20/800 条 (2.5%)
⏳ QWEN: 0/800 条 (待开始)

总计: 820 条
预计最终: 2400 条（800×3）
```

### 数据质量
```
平均组合质量: 0.79
平均生成质量: 0.90
平均文本长度: 1023 字符
文本长度范围: 260-1687 字符
```

### 维度分布
```
话题: 39个（实际生成）
文体: 20个
角色: 15个
风格: 10个
约束: 8个
属性: 5个

理论组合数: 39×20×15×10×8×5 = 936,000 种
实际使用: 800 种（0.09%）
```

---

## 总结

原代码实现了一个**精巧的AI文本生成框架**，核心是：
1. **六维组合** → 生成多样化提示词
2. **智能匹配** → 确保组合合理性
3. **质量控制** → 两级评分筛选
4. **多模型** → 理论支持并行生成

但存在致命缺陷：
- **缺少人类样本对比**（无法训练检测器）
- **实际只用单一模型**（过拟合风险）
- **话题重复严重**（多样性不足）
- **格式过于统一**（易被识别）

**改进方向：** 见《AI检测数据集改进计划_20260106.md》
