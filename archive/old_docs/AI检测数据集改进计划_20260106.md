# AI vs 人类文本二分类数据集改进计划

## 项目目标
构建大规模、平衡的AI文本检测训练数据集（50000条），用于训练通用AI文本检测器

## 核心问题分析

### 当前项目优势
- ✅ 六维组合框架完善（属性×话题×文体×角色×风格×约束）
- ✅ 已生成680条高质量AI样本（质量评分0.9）
- ✅ 完整的自动化生成流程和质量评估机制

### 关键缺陷
- ❌ **缺少人类样本**（100%正例偏差，无法训练二分类器）
- ❌ **单一模型源**（仅custom API，导致过拟合）
- ❌ **话题重复严重**（39个话题，平均17.9次/话题）
- ❌ **格式过于统一**（86.7%含Markdown标记）
- ❌ **AI特征明显**（无自然变异、错误、口语化）

---

## 数据集构成方案（总计50000条）

### AI样本：25000条（50%）
| 模型 | 数量 | 占比 | 状态 |
|------|------|------|------|
| Custom (gpt-4o-mini) | 10000 | 40% | 已配置 |
| DeepSeek | 8000 | 32% | 已配置但未使用 |
| Qwen（通义千问） | 7000 | 28% | 已配置但未使用 |

### 人类样本：25000条（50%）
| 数据源 | 数量 | 领域 | 获取方式 |
|--------|------|------|---------|
| CCI 3.0-HQ | 8000 | 新闻/博客/论坛 | 智源研究院开源 |
| 搜狐新闻 | 6000 | 时政/财经/科技 | 9.7亿条可选 |
| 知乎KOL | 5000 | 多领域问答 | HuggingFace |
| 百度知道 | 3000 | 生活/技术 | 10000条开源 |
| THUCNews | 2000 | 新闻分类 | 清华开源 |
| 微博数据 | 1000 | 社交短文本 | 多个开源集 |

---

## 实施方案

### 阶段一：激活多模型生成（1-3天，优先级P0）

#### 核心修改
**文件：** `/mnt/c/datacollection/new data collection.py`

**修改1：启用所有模型（第765行）**
```python
# 当前
SAMPLES_PER_MODEL = 800
ACTIVE_MODELS = list(active_clients.keys())  # 实际只用了custom

# 改为
SAMPLES_PER_MODEL = {
    "custom": 10000,
    "deepseek": 8000,
    "qwen": 7000
}
ACTIVE_MODELS = ["custom", "deepseek", "qwen"]
```

**修改2：增加话题多样性（第430-434行）**
```python
# 当前：50个话题导致重复17.9次
topics = self.auto_gen.generate_with_cache(
    f"topics_{datetime.now().strftime('%Y%m%d')}",
    self.auto_gen.generate_topics,
    num_topics=50
)

# 改为：200个话题降低重复率
num_topics=200  # 目标：每个话题<5次重复
```

**修改3：格式变异机制（第597-617行）**
在 `_generate_prompt` 方法中添加：
```python
# 30%要求Markdown，30%禁止，40%不限制
format_instruction = random.choices(
    ["请使用Markdown格式组织内容",
     "请使用纯文本格式，不要使用Markdown标记",
     ""],
    weights=[0.3, 0.3, 0.4]
)[0]
```

**执行步骤：**
1. Day 1上午：修改配置，测试三个模型各生成100条验证
2. Day 1下午-Day 2：正式运行生成25000条（预计24-36小时）
3. Day 3：质量检查和数据整理

**预期产出：** 25000条AI样本，模型分布均衡

---

### 阶段二：人类样本采集（1-2周，优先级P1）

#### 第一周：核心数据集处理

**新建文件：** `/mnt/c/datacollection/human_data_processor.py`

**核心功能：**
```python
class HumanDataProcessor:
    def clean_text(self, text):
        """标准清洗：去HTML、URL、特殊符号"""

    def filter_quality(self, text):
        """质量过滤：长度(100-2000字)、完整性、重复检查"""

    def match_ai_distribution(self, human_samples, ai_samples):
        """使人类样本的长度/领域分布匹配AI样本"""
```

**数据下载清单：**
- CCI 3.0-HQ: http://open.flopsera.com/flopsera-open/details/BAAI-CCI2
- 搜狐新闻: https://dianshudata.com/dataDetail/11991
- 知乎KOL: https://huggingface.co/datasets/wangrui6/Zhihu-KOL

**执行步骤：**
- Day 1-2：下载CCI和搜狐数据
- Day 3-4：编写预处理脚本
- Day 5-7：清洗和采样15000条

#### 第二周：补充数据和质量控制

**新建文件：** `/mnt/c/datacollection/quality_controller.py`

**质量控制体系：**
- 内容完整性（30%）：包含主题信息
- 语言流畅性（25%）：无明显语法错误
- 信息密度（20%）：实质内容>60%
- 领域适配性（15%）：符合领域特征
- 安全合规性（10%）：无违禁敏感内容

**执行步骤：**
- Day 8-10：下载补充数据源（知乎、百度、THUCNews、微博）
- Day 11-12：运行可比性检查，调整分布
- Day 13-14：质量评估和最终筛选

**预期产出：** 25000条高质量人类样本

---

### 阶段三：数据集集成（1周，优先级P2）

#### 合并与标注
```python
# 数据集结构
{
    'text': str,              # 文本内容
    'label': int,             # 0=人类, 1=AI
    'source': str,            # 具体来源
    'model': str,             # AI模型名称（如果是AI）
    'topic': str,             # 话题类别
    'genre': str,             # 文体类型
    'length': int,            # 文本长度
    'quality_score': float    # 质量评分
}
```

#### 数据集划分
- 训练集：35000条（70%）
- 验证集：7500条（15%）
- 测试集：7500条（15%）

#### 基线模型验证
- 训练简单的BERT分类器
- 目标准确率：>80%
- 验证数据集质量

**预期产出：** 完整的50000条标注数据集

---

## 增强改进（可选，长期优化）

### 自然变异处理器（中期优化）
**新建文件：** `/mnt/c/datacollection/natural_variation_processor.py`

为AI文本添加自然瑕疵：
- 错别字（5%文本）：的→得，在→再
- 口语化（10%文本）：非常→特别，很
- 语气词（15%文本）：啊、呢、吧
- 不完整句（5%文本）：省略号、中断

应用策略：30%的AI文本应用轻度变异

---

## 关键文件清单

### 需要修改的文件
1. `/mnt/c/datacollection/new data collection.py`
   - 第765行：多模型配置
   - 第430-434行：话题数量
   - 第597-617行：格式变异

### 需要新建的文件
2. `/mnt/c/datacollection/human_data_processor.py` - 人类样本预处理
3. `/mnt/c/datacollection/quality_controller.py` - 质量控制
4. `/mnt/c/datacollection/natural_variation_processor.py` - 自然变异（可选）

---

## 预期效果

### 数据集指标改进
| 指标 | 当前 | 目标 |
|-----|------|------|
| 总样本数 | 680 | 50000 |
| 模型多样性 | 1种 | 3种 |
| 话题重复率 | 17.9次 | <5次 |
| Markdown占比 | 86.7% | ~40% |
| 人类样本 | 0% | 50% |

### 模型性能预期
- 准确率：>85%
- F1分数：>0.83
- AUC-ROC：>0.90
- 跨模型泛化：>80%

---

## 风险与应对

### 潜在风险
1. **API成本**：25000条AI样本预计$50-100
   - 应对：分批生成，设置预算上限

2. **数据下载受限**：部分数据集需要申请
   - 应对：优先使用完全开源数据集

3. **分布不匹配**：AI和人类样本差异过大
   - 应对：实时监控可比性指标，动态调整

4. **质量下降**：多样化可能降低整体质量
   - 应对：设置质量阈值>0.6，宁缺毋滥

---

## 实施时间表

### 短期（1-3天）
- ✅ 修改配置启用3个模型
- ✅ 生成25000条AI样本

### 中期（1-2周）
- ✅ 下载并处理人类数据集
- ✅ 采样25000条人类样本
- ✅ 质量控制和分布匹配

### 长期（1个月+）
- 扩展到100000条
- 添加更多LLM模型
- 构建垂直领域子集
- 困难样本库建设

---

## 成功标准

1. ✅ 数据集规模达到50000条（AI 25000 + 人类 25000）
2. ✅ AI样本覆盖3个模型，分布均衡
3. ✅ 人类样本来自至少4个不同数据源
4. ✅ AI和人类样本长度/领域分布通过KS检验（p>0.05）
5. ✅ 基线BERT模型准确率>80%
6. ✅ 完整的数据集文档和元数据标注
