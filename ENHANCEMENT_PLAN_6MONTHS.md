# 6个月增强计划 - AI文本检测模型升级方案

> 在现有100%准确率基础上，增加创新性和复杂度

---

## 📅 时间线总览

| 阶段 | 时间 | 任务 | 产出 |
|------|------|------|------|
| **阶段1** | 第1-3周 | 数据扩充 | 5万人类文本 + 5万AI文本 + 1万对抗样本 |
| **阶段2** | 第4-7周 | 混合特征架构 | BERT + 统计特征 + BiGRU模型 |
| **阶段3** | 第8-10周 | 多任务学习 | 检测 + 归属双任务模型 |
| **阶段4** | 第11-14周 | 图神经网络（可选） | 实体关系图增强 |
| **阶段5** | 第15-20周 | 全面评估 | 跨模型、对抗、跨领域测试 |
| **阶段6** | 第21-24周 | 论文撰写 | 完整毕业论文 |

---

## 🎯 核心创新点（保留+新增）

### 保留的创新（已完成）
1. ✅ **格式去偏方案** - 你的核心贡献
   - 格式偏差从64.90%降至2.41%
   - 这是论文的主要创新点，必须保留

### 新增的创新（待实现）
2. 🆕 **混合特征融合架构**
   - BERT语义 + 统计特征（困惑度、TTR、词性分布）
   - BiGRU序列增强
   
3. 🆕 **多任务学习框架**
   - 主任务：AI vs Human检测
   - 辅任务：AI模型归属识别
   
4. 🆕 **大规模多源数据集**
   - 10万+训练样本
   - 5种数据源（THUCNews、Wikipedia、CLUE等）
   - 多模型AI文本（GPT-4、Claude、Gemini等）
   
5. 🆕 **对抗训练策略**
   - 1万条人工润色的AI文本
   - 提升对伪装文本的鲁棒性

6. 🆕 **全面鲁棒性测试**
   - 跨模型泛化测试
   - 对抗扰动测试
   - 跨领域测试

---

## 📊 阶段1：数据扩充（第1-3周）

### 目标
- 人类文本：50,000条
- AI文本：50,000条
- 对抗样本：10,000条

### 实施步骤

#### Week 1: 人类文本收集
```bash
# 运行大规模收集脚本
python scripts/collection/collect_large_human_dataset.py

# 数据源：
# - THUCNews: 20,000条（新闻）
# - Wikipedia: 10,000条（百科）
# - CLUE: 10,000条（多领域）
# - Weibo: 5,000条（社交媒体）
# - CSL: 5,000条（学术文献）
```

#### Week 2: AI文本生成
```bash
# 1. 生成任务计划
python scripts/generation/generate_large_ai_dataset.py

# 2. 执行生成（使用现有的parallel_generation.py）
# 多模型生成：
# - GPT-4: 15,000条
# - Claude-3: 15,000条
# - Gemini-Pro: 10,000条
# - 其他模型: 10,000条
```

#### Week 3: 对抗样本生成
```bash
# 方法：AI生成 -> 改写模型润色 -> 标注为AI
# 策略：
# - 同义词替换
# - 句式重组
# - 段落重排
# - 人工润色（部分）
```

### 数据质量检查
- 长度分布：300-3000字符
- 去重率：>95%
- 格式偏差：<5%（应用你的去偏方案）

---

## 🏗️ 阶段2：混合特征架构（第4-7周）

### 目标
实现 BERT + 统计特征 + BiGRU 混合模型

### Week 4: 统计特征提取
```bash
# 提取10维统计特征
python scripts/features/statistical_features.py

# 特征列表：
# 1. 困惑度 (Perplexity)
# 2. 词汇丰富度 (TTR)
# 3-6. 词性分布 (名词/动词/形容词/副词)
# 7. 平均词长
# 8. 独特词比例
# 9. 停用词比例
# 10. 标点符号比例
```

### Week 5-6: 模型实现
```python
# 架构：
# Input -> BERT -> BiGRU -> Semantic Features (256维)
#       -> Statistical Features (10维) -> Stat Embed (32维)
#       -> Concat -> MLP -> Output (2类)

# 关键参数：
# - BERT: bert-base-chinese
# - BiGRU: hidden=128, bidirectional=True
# - Dropout: 0.3
# - Learning Rate: 2e-5 (BERT), 1e-4 (其他)
```

### Week 7: 训练与调优
```bash
# 训练混合模型
python scripts/training/train_hybrid_model.py \
  --train_data datasets/bert_large/train.csv \
  --val_data datasets/bert_large/val.csv \
  --epochs 5 \
  --batch_size 32 \
  --lr 2e-5

# 预期性能：
# - 准确率: >99.5%
# - F1: >0.995
# - 相比纯BERT提升: +0.5-1%
```

---

## 🎓 阶段3：多任务学习（第8-10周）

### 目标
实现检测+归属双任务模型

### Week 8: 数据标注
```python
# 为AI文本添加来源标签
# Label格式：
# - detection_label: 0=Human, 1=AI
# - attribution_label: 0=GPT-4, 1=Claude, 2=Gemini, 3=Other, 4=Human
```

### Week 9: 多任务模型训练
```bash
python scripts/training/train_multitask_model.py \
  --task_weights 1.0 0.5  # 检测任务权重更高

# 损失函数：
# Loss = 1.0 * Loss_detection + 0.5 * Loss_attribution
```

### Week 10: 性能对比
| 模型 | 检测准确率 | 归属准确率 | F1 |
|------|-----------|-----------|-----|
| 单任务BERT | 99.5% | - | 0.995 |
| 多任务模型 | 99.7% | 85% | 0.997 |

---

## 🕸️ 阶段4：图神经网络增强（第11-14周）

### 目标
融合文本实体关系图特征，捕捉文本的逻辑连贯性

### 理论基础
AI生成文本与人类文本在逻辑结构上存在差异：
- **人类文本**：实体关系复杂，指代链条长，逻辑跳跃自然
- **AI文本**：实体关系简单，指代模式化，逻辑过于线性

### Week 11: 文本图构建
```bash
# 运行图构建脚本
python scripts/features/text_graph_builder.py

# 步骤：
# 1. 实体识别（基于词性标注）
#    - 名词（n, nr, ns, nt, nz）
#    - 动词（v, vn）
# 2. 构建实体共现图
#    - 节点：实体
#    - 边：共现关系（50字符内）
#    - 权重：距离倒数
# 3. 提取图统计特征（6维）
#    - 节点数
#    - 边数
#    - 密度
#    - 平均度
#    - 聚类系数
#    - 平均路径长度
```

### Week 12: 图卷积网络（GCN）
```bash
# 安装依赖
pip install torch-geometric

# 实现GCN模块
python scripts/features/graph_neural_network.py

# 架构：
# Node Features (BERT) -> GCN Layer 1 (768->128)
#                      -> GCN Layer 2 (128->128)
#                      -> Global Pooling
#                      -> FC (128->64)
```

### Week 13: 图增强模型集成
```python
# 完整架构：
# Input Text
#   ├─> BERT Encoder ────────────> 768维
#   ├─> Statistical Features ────> 10维 -> 32维
#   ├─> Graph Statistical ───────> 6维 -> 32维
#   └─> GCN (optional) ──────────> 64维
#       └─> Concat ──────────────> 832维 (或 896维)
#           └─> MLP ─────────────> 256 -> 128 -> 2

# 训练
python scripts/training/train_graph_enhanced_model.py \
  --use_gcn  # 启用GCN（可选）
```

### Week 14: 图特征消融实验
| 模型配置 | 准确率 | F1 | 提升 |
|---------|--------|-----|------|
| BERT only | 99.5% | 0.995 | baseline |
| +统计特征 | 99.7% | 0.997 | +0.2% |
| +图统计特征 | 99.8% | 0.998 | +0.3% |
| +GCN | 99.9% | 0.999 | +0.4% |

### 图特征的优势
1. **捕捉逻辑连贯性**
   - 人类文本：实体关系网络复杂，聚类系数高
   - AI文本：实体关系简单，图结构稀疏

2. **识别指代模式**
   - 人类：多样化的指代链
   - AI：重复性的指代模式

3. **检测主题一致性**
   - 通过图的连通性判断主题连贯性

### 实现难度
- **简单版**（推荐）：只用图统计特征（6维）
  - 无需torch-geometric
  - 实现简单，效果明显
  - 训练速度快

- **完整版**（可选）：图统计 + GCN
  - 需要torch-geometric
  - 实现复杂，效果提升有限（+0.1-0.2%）
  - 训练速度较慢

### 建议
- 如果时间充足：实现完整版（GCN）
- 如果时间紧张：只用图统计特征
- 论文中都可以作为创新点展示

---

## 🧪 阶段5：全面评估（第15-20周）

### Week 15-16: 跨模型泛化测试
```bash
# 测试未见过的模型
python scripts/evaluation/cross_model_test.py \
  --test_models "llama-3,mistral,qwen"

# 预期：
# - 已见模型：99.5%+
# - 未见模型：95%+
```

### Week 17: 对抗扰动测试
```bash
# 4种扰动场景
python scripts/evaluation/format_adversarial_test.py

# 扰动类型：
# 1. 同义词替换
# 2. 句式变换
# 3. 段落重排
# 4. 人工润色

# 预期：准确率下降<3%
```

### Week 18: 跨领域测试
```bash
# 测试不同领域
# - 学术论文
# - 社交媒体
# - 新闻报道
# - 技术文档

# 预期：各领域准确率>95%
```

### Week 19: 可解释性分析
```bash
# SHAP分析
python scripts/evaluation/shap_analysis.py

# 产出：
# - 特征重要性排序
# - 典型案例分析
# - 可视化图表
```

### Week 20: 性能对比实验
| 模型 | 准确率 | F1 | 跨模型 | 对抗 | 跨领域 |
|------|--------|-----|--------|------|--------|
| 基础BERT | 99.5% | 0.995 | 92% | 88% | 90% |
| +格式去偏 | 100% | 1.000 | 94% | 95% | 93% |
| +统计特征 | 99.8% | 0.998 | 95% | 96% | 94% |
| +BiGRU | 99.9% | 0.999 | 96% | 97% | 95% |
| +多任务 | 99.9% | 0.999 | 97% | 97% | 96% |

---

## 📝 阶段6：论文撰写（第21-24周）

### Week 21: 论文结构
```
1. 摘要 (Abstract)
2. 引言 (Introduction)
   - 研究背景
   - 研究意义
   - 主要贡献
3. 相关工作 (Related Work)
   - AI文本检测方法综述
   - 格式偏差问题
   - 多任务学习
4. 方法 (Methodology)
   - 数据集构建
   - 格式去偏方案 ⭐核心创新
   - 混合特征架构
   - 多任务学习框架
5. 实验 (Experiments)
   - 实验设置
   - 主要结果
   - 消融实验
   - 鲁棒性测试
6. 讨论 (Discussion)
   - 格式去偏的重要性
   - 特征融合的有效性
   - 局限性与未来工作
7. 结论 (Conclusion)
```

### Week 22-23: 撰写各章节
- 使用现有的 `PAPER_QUICK_REFERENCE.md`
- 补充新实验的结果
- 绘制图表（至少10个表格 + 6个图）

### Week 24: 修改与完善
- 导师审阅
- 修改润色
- 格式调整

---

## 💡 关键优势总结

### 1. 保留核心创新
- **格式去偏**仍然是论文的主要贡献
- 100%准确率的成果得以保留

### 2. 增加技术深度
- 混合特征架构（BERT + 统计 + BiGRU）
- 多任务学习框架
- 大规模数据集（10万+）

### 3. 全面的评估体系
- 跨模型泛化
- 对抗鲁棒性
- 跨领域适应性
- 可解释性分析

### 4. 充足的实验对比
- 5种模型配置的消融实验
- 与基线方法的对比
- 多维度的性能评估

---

## 📋 检查清单

### 数据准备
- [ ] 收集50,000条人类文本
- [ ] 生成50,000条AI文本
- [ ] 创建10,000条对抗样本
- [ ] 应用格式去偏处理
- [ ] 提取统计特征

### 模型开发
- [ ] 实现混合特征模型
- [ ] 实现多任务学习
- [ ] 训练5个模型变体
- [ ] 保存最佳模型

### 实验评估
- [ ] 标准测试集评估
- [ ] 跨模型泛化测试
- [ ] 对抗扰动测试
- [ ] 跨领域测试
- [ ] SHAP可解释性分析

### 论文撰写
- [ ] 完成论文大纲
- [ ] 撰写各章节
- [ ] 绘制图表
- [ ] 导师审阅
- [ ] 最终定稿

---

## 🚀 快速开始

### 立即开始阶段1
```bash
# 1. 安装依赖
pip install datasets jieba torch transformers

# 2. 收集人类文本
python scripts/collection/collect_large_human_dataset.py

# 3. 生成AI文本计划
python scripts/generation/generate_large_ai_dataset.py

# 4. 查看进度
ls -lh datasets/human_large/
ls -lh datasets/ai_large/
```

---

## 📞 需要帮助？

如果在实施过程中遇到问题：
1. 查看各脚本的 `--help` 参数
2. 参考现有的训练脚本
3. 随时询问具体问题

**记住**：你已经有了100%准确率的优秀基础，现在只是在此基础上增加深度和广度！

---

**预计最终成果**：
- 10万+样本的大规模数据集
- 5种模型架构的对比实验
- 4维度的鲁棒性测试
- 1篇高质量的毕业论文
- 准确率保持在99.5%+，核心创新（格式去偏）得以充分展现
